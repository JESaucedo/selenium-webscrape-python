#necessary to use selenium
from selenium import webdriver
from selenium.webdriver.common.by import By
import time
import sys
SCROLL_PAUSE_TIME = 1


original_stdout = sys.stdout


#the links needed to webscrape
url = 'https://www.youtube.com/playlist?list=PL4AA27D7B17941523'
url3 = 'https://www.youtube.com/@chugga/videos'



#this is where it opens firefox and uses the url
driver = webdriver.Firefox()
#driver.get(url)
driver.get(url3)



#uses wait to make sure the page loads
driver.implicitly_wait(30)



#used to scroll all the way to the bottom of the page
last_height = driver.execute_script("return document.documentElement.scrollHeight")

while True:
	driver.execute_script("window.scrollTo(0, arguments[0]);", last_height)
	
	time.sleep(SCROLL_PAUSE_TIME)

	new_height = driver.execute_script("return document.documentElement.scrollHeight")
	if new_height == last_height:
		break
	last_height = new_height


#gets all the elements found in the TAG_NAME "a"
videos = driver.find_elements(By.TAG_NAME, "a")


#uses this to filter out which videos are added to the file
findString = "Luigi's Mansion"


#writes the list of videos to a named file
with open('Luigi_Mansion_Videos.txt', 'w') as f:
	for video in videos:
		title = video.get_attribute("title")
		href = video.get_attribute("href")
		if findString in video.text:
			#print(title)
			f.write(title)
			f.write("\n")
			#print(href)
			f.write(href)
			f.write("\n")
	
